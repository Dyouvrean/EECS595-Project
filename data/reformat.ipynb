{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_QA = [\n",
    "    r\"../data/train_df-arc_challenge.csv\",\n",
    "    r\"../data/test_df-arc_challenge.csv\",\n",
    "    r\"../data/train_df-ARC-Easy.csv\",\n",
    "    r\"../data/test_df-ARC-Easy.csv\",\n",
    "    r\"../data/train_df_common.csv\",\n",
    "    r\"../data/valid_df-arc_challenge.csv\",\n",
    "    r\"../data/valid_df-ARC-Easy.csv\",\n",
    "    r\"../data/dev_df_common.csv\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_ce =[\n",
    "     r\"../data/train_df-CE.csv\",\n",
    "     r\"../data/test_df-CE.csv\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(ans):\n",
    "    choice = ans[0]\n",
    "    short = ans[3:]\n",
    "    return \"the correct choice is {} which is {}.\".format(choice,short.strip(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_reformat(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df[\"Answer\"] = df[\"Answer\"].apply(reformat)\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in csv_QA:\n",
    "    batch_reformat(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_ce(ans):\n",
    "    ans=ans.split(\". \")\n",
    "    entail = ans[0].split(\": \")\n",
    "    Type = ans[1].split(\": \")\n",
    "    return \"the Entailment is {} and its type is {}\".format(entail[1],Type[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ce_format(file_path):\n",
    "    df=pd.read_csv(r\"../data/test_df-CE.csv\")\n",
    "    df[\"Label\"] = df[\"Label\"].apply(reformat_ce)\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in csv_ce:\n",
    "    ce_format(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_Trip=[\n",
    "    r\"../data/train_df-TRIP.csv\",\n",
    "    r\"../data/test_df-TRIP.csv\",\n",
    "    r\"../data/valid_df-TRIP.csv\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset trip (C:/Users/dry19/.cache/huggingface/datasets/sled-umich___trip/default/1.0.1/6e4c49afb825381fbdd640ee9352cca3e083d46acf090aa4a804872ef65dcea8)\n",
      "100%|██████████| 6/6 [00:00<00:00, 249.77it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"sled-umich/TRIP\")\n",
    "train_order_ds = dataset[\"OrderDev\"]\n",
    "train_cloze_ds = dataset[\"ClozeDev\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_trip_to_dataframe_order(dataset, custom_instruction):\n",
    "    \"\"\"\n",
    "    Transforms the TRIP dataset into a DataFrame with numbered stories and their detailed attributes.\n",
    "    \n",
    "    :param dataset: List of dictionaries, each containing multiple stories.\n",
    "    :return: A pandas DataFrame with the transformed data.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    for entry in dataset:\n",
    "        for story in entry['stories']:\n",
    "            # Numbering and concatenating the sentences to form the story\n",
    "            story_text = f\"Actor: {story['actor']}, Location: {story['location']}, Story: \"\n",
    "            story_text += ' '.join(f\"[{i}] {sentence}\" for i, sentence in enumerate(story['sentences']))\n",
    "            story_text += \"\\n\" + custom_instruction\n",
    "\n",
    "            # Compiling story details\n",
    "            pla= True if story['plausible'] else False\n",
    "            \n",
    "            breakp= story['breakpoint']\n",
    "            conflict = story['confl_sents']\n",
    "            Type = story.get('type', 'N/A')\n",
    "            detail=''\n",
    "            if pla:\n",
    "                detail = \"The sentences are plausible without any conflict.\"\n",
    "            else:\n",
    "                detail = \"The sentences are not plausible. The breakpoint sentence is sentence {} as it is conflicting with sentence {}. The conflict type is {} \".format(\n",
    "                    breakp,conflict,Type\n",
    "                )\n",
    "            data.append([story_text, detail])\n",
    "\n",
    "    return pd.DataFrame(data, columns=['Story', 'Details'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_cloze_to_dataframe(dataset, cloze_ci):\n",
    "    \"\"\"\n",
    "    Transforms the ClozeTrain part of the TRIP dataset into a DataFrame.\n",
    "    \n",
    "    :param dataset: List of dictionaries, each containing multiple cloze stories.\n",
    "    :return: A pandas DataFrame with the transformed data.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    for entry in dataset:\n",
    "        for story in entry['stories']:\n",
    "            # Numbering and concatenating the sentences to form the story\n",
    "            story_text = f\"Actor: {story['actor']}, Location: {story['location']}, Story: \"\n",
    "            story_text += ' '.join(f\"[{i}] {sentence}\" for i, sentence in enumerate(story['sentences']))\n",
    "            story_text += \"\\n\" + cloze_ci\n",
    "\n",
    "            # Compiling story details\n",
    "            pla= True if story['plausible'] else False\n",
    "            \n",
    "            breakp= story['breakpoint']\n",
    "            conflict = story['confl_sents']\n",
    "            Type = story.get('type', 'N/A')\n",
    "            pair = story['confl_pairs']\n",
    "            detail=''\n",
    "            if pla:\n",
    "                detail = \"The sentences are plausible without any conflict.\"\n",
    "            else:\n",
    "                detail = \"The sentences are not plausible. The breakpoint sentence is sentence {} as it is conflicting with sentence {}.The conflict pair is {}. The conflict type is {} \".format(\n",
    "                    breakp,conflict,pair,Type\n",
    "                )\n",
    "            data.append([story_text, detail])\n",
    "\n",
    "            # details = (f\"Plausible: {'True' if story['plausible'] else 'False'}, \"\n",
    "            #            f\"Breakpoint: {story['breakpoint']}, \"\n",
    "            #            f\"Conflict Sentences: {story['confl_sents']}, \"\n",
    "            #            f\"Conflict Pairs: {story['confl_pairs']}, \"\n",
    "            #            f\"Type: {story.get('type', 'N/A')}\")\n",
    "\n",
    "            data.append([story_text, detail])\n",
    "\n",
    "    return pd.DataFrame(data, columns=['Story', 'Details'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(786, 2)\n",
      "(1288, 2)\n",
      "(2074, 2)\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "ci = \"Instruction: Please review each story, paying special attention to the numbered sentences. Identify the key sentence or sentences that disrupt the logical consistency or narrative coherence. Evaluate whether the overall sequence of events aligns with real-world physics, and determine the plausibility of the story based on these observations. Specifically highlight any sentences that contribute to making the story implausible.\"\n",
    "order_df = transform_trip_to_dataframe_order(train_order_ds, ci)\n",
    "print(order_df.shape)\n",
    "\n",
    "\n",
    "cloze_ci = \"Instruction: Examine each story, focusing on numbered and conflicting sentences. Analyze their interplay and impact on narrative coherence and plausibility. Determine the story's alignment with intuitive physics and logical consistency, highlighting key elements that affect its plausibility.\"\n",
    "cloze_df = transform_cloze_to_dataframe(train_cloze_ds, cloze_ci)\n",
    "print(cloze_df.shape)\n",
    "\n",
    "train_df = combined_df = pd.concat([order_df, cloze_df], ignore_index=True)\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../data/valid_df-TRIP.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EECS595project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
